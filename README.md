# Fake Face Detection: FaceAuth

DeepLearning Final Project

In the era of advanced artificial intelligence, the ability to discern between human-generated and AI- generated images has become crucial, this is especially true for AI generated human faces. This project aims to develop a image classification model capable of distinguishing between faces of real humans and those
generated by AI. Additionally, we hope to develop an auxiliary classification model that will be extended to identify the specific AI architecture responsible for generating the image, including state-of-the-art models like DALL-E, Imagen, and others.

We undertook a fairly deep literature review to identify the current state-of the art solution to this
problem but we could not find any such model. Although, we did find commercial solutions that claim to be
able to detect Deep-Fakes like sensity.ai but they do not publish the kind of models they are using neither
can their effectiveness be evaluated by us.

The Code folder has multiple files. All the models have seperate train files. Names are organized as train\_{model_name}.py.

The train files have argument parser in them. All the train files have 4 argparsers, '-c' -> It means continue from the last saved model and run it for further epochs.
'e' -> It tells us about the excel file to use for training. '-n'-> It tells us the name to save the summary and models from the train file. '--dry' -> Use this if you just want to dry run the code to fix bugs.

Suppose, we have to run the train_Densenet.py file on the excel 'fully_processed.py', we will run the command python3 train_densenet.py -e fully_processed.xlsx -n Densenet

equal_distribution.xlsx -> equally distributed train, test, dev with equal distibution of gan, diffusion, real image

And using move_train_test_split.py, we move the files to train, test and dev folders based on these files

in fully_processed.xlsx we have the split of the final files and also the output processed as real/fake -> 1/0

fully_processed.xlsx is generally used to train our models on the whole dataset.

To download the models, we just need to run the shell script called download_models.sh using ./download_models.sh command on linux terminal.

To download the dataset, we need to run the shell script called 1mFakeFaces_Download.sh using ./1mFakeFaces_Download.sh on linux terminal.

Instructions to download all the other datasets are mentioned in the files namely, CelebA-HQ-256_Download.txt, DeepFakeFace_Download.txt, and iFakeFaceDB_Download.txt.

The dataset is divided into train, test, and dev.

train set is used to train and test set set is used the check the performance of the model and then cherry pick to improve the performance of the model.

dev set is just used once to get the final results of the model.

Every model has a test\_{model_name}.py file. To test the model on the dev set can be done using python3 test_densenet.py --split dev
